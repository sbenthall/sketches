{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontier Notation\n",
    "\n",
    "This notebook considers the design and implementation of the next generation of heterogenous agent model (HAM) notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "### Bellman Equation\n",
    "\n",
    "A [Bellman equation](https://en.wikipedia.org/wiki/Bellman_equation) is a formulation of the value to an agent of each state acting optimally within a dynamic decision problem. From this value function it is easy to compute the optimal policy for the agent. The Bellman equation takes the form (**Definition 1**):\n",
    "\n",
    "$$V(x) = \\text{max}_{a \\in \\Gamma(x)} F(x,a) + \\beta V(T(x,a))$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $a \\in A$, the set of actions available\n",
    "* $x \\in X$, the set of states\n",
    "* $\\Gamma : X \\rightarrow \\mathscr{B}(A)$ constraints the actions available in state X\n",
    "* $F(x,a)$ is the payoff to the agent of taking action $a$ in state $x$\n",
    "* $T: X \\times A \\rightarrow X$ is a transition function determining the state in the next period\n",
    "* $\\beta$ is a discount factor on future payoffs.\n",
    "\n",
    "This representation of Bellman equation assumes a deterministic model. If T is a stochastic function, as it is in many cases in economics, then the value function is defined in terms of expectations. (**Definition 2**):\n",
    "\n",
    "$$V(x) = \\text{max}_{a \\in \\Gamma(x)} F(x,a) + \\beta E[V(T(x,a))]$$\n",
    "\n",
    "We will use the deterministic version of this equation for simplicity unless there's a good reason to use the probabilistic version.\n",
    "\n",
    "Note that with this rendition of the problem, there is only one state space, action space, value function, etc. that is repeated \"over time\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variations\n",
    "\n",
    "The above formulation of the Bellman equation assumes that the problem is structured identically at every control point (opportunity for the agent to choose an action $a$) and that there is only one control point. For various applications in economics, we are interested in other kinds of problems, such as those with:\n",
    "\n",
    "* **V1**. Multiple control points\n",
    "* **V2**. Inconsistent problems over time\n",
    "\n",
    "While it may be tempting to consider these the same kind of challenge, we will examine each case rigorously in isolation and see if that conclusion can be confirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1. Multiple control points\n",
    "\n",
    "**V1** (Variation 1) can be understood as a decomposition of the problem described in **Definition 1**. For reasons connected to those described in \"Mathematics of Discrete Time Stochastic Control Processes in Macroeconomics\", problems of the following form, for $C$ (sequential) control variables, can be shown to have an equivalent problem in the above form: (Note that the variables here are in italic font)\n",
    "\n",
    "* $(\\mathit{A}_0, ..., \\mathit{A}_C)$ is a sequence of sets of action spaces such that $A = \\mathit{A}_0 \\times ... \\times \\mathit{A}_c$\n",
    "* $(\\mathit{X}_0, ...,\\mathit{X}_C)$ is a sequence of sets of state spaces such that $X = \\mathit{X}_0 \\times ... \\times \\mathit{X}_c$\n",
    "* $(\\mathit{\\Gamma}_0, ..., \\mathit{\\Gamma}_C)$ is a sequence of contraints. $\\mathit{\\Gamma}_c: \\mathit{X}_c \\rightarrow \\mathscr{B}(\\mathit{A}_c)$\n",
    "* $(\\mathit{F}_0, ..., \\mathit{F}_C)$ is a sequence reward functions. $\\mathit{F}_c: \\mathit{X}_c \\times \\mathit{A}_c \\rightarrow \\mathbb{R}$\n",
    "* $(\\mathit{T}_0, ..., \\mathit{T}_C)$ is a sequence of transitions functions $\\mathit{T}_c: \\mathit{X}_c \\times \\mathit{A}_c \\rightarrow \\mathit{X}_{(c+1) mod C}$. **Note incrementing of state space in transition function.**\n",
    "* *Unknown:* What happens to $\\beta$ the discount factor?\n",
    "\n",
    "With these sequences of subproblems defined, the decomposed into $C$ mutually recursive Bellman-like *Carroll equations* for $x \\in \\mathit{X}_c$ is:\n",
    "\n",
    "$$\\mathit{V}_c(x) = \\text{max}_{a \\in \\mathit{\\Gamma}_c(x)} \\mathit{F}_c(x,a) + \\beta \\mathit{V}_{(c+1) mod C}(\\mathit{T}_c(x,a))$$\n",
    "\n",
    "In principle, the original problem could be defined in such a way that the sub-problems need not have a natural sequential order. However, in these cases multiple ordering will suffice.\n",
    "\n",
    "Note that these subproblems are not isolated from each other. The transition function $\\mathit{T}_c$ of each problem contains a \"reference\" to the state space in the next \"stage\" $\\mathit{X}_{c+1}$.\n",
    "\n",
    "These truly are \"subproblems\" of the original problem specification, as the original specification can be reconstituted from the details of the subproblems. For example, $A = \\mathit{A}_0 \\times ... \\times \\mathit{A}_c$, $X = \\mathit{X}_0 \\times ... \\times \\mathit{X}_c$ and so on. The problem remains an infinite horizon problem, but decomposed into $C$ simpler sub-problems with reduced action and state spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2. Inconsistent problems over time\n",
    "\n",
    "There is a sense in which the challenge of inconsistency over time is similar to the challenge of multiple control points. We will see that the formal descriptions of the challenges are similar. However, there are some differences:\n",
    "\n",
    "1. Whereas multiple control points allow us to break a problem down into $C$ subproblems with smaller state and action spaces than the original problem, inconsistency over time makes a problem *more* complex because it *increases* the size of the problem.\n",
    "2. One of these things will hold for any actually specified inconsistent problem: (a) the inconsistent problem is a finite problem, or (b) the inconsistent problem can be rewritten as a consistent problem with time index in its state space.\n",
    "\n",
    "We will formally define the time inconsistent problem in terms of the following, assuming for now that it is a finite problem:\n",
    "\n",
    "* $A_0, ..., A_K$ is a sequence of sets of action spaces\n",
    "* $X_0, ...,X_K$ is a sequence of sets of state spaces\n",
    "* $\\Gamma_0, ..., \\Gamma_C$ is a sequence of contraints. $\\Gamma_k: X_k \\rightarrow \\mathscr{B}(A_k)$\n",
    "* $F_0, ..., F_K$ is a sequence reward functions. $F_k: X_k \\times A_k \\rightarrow \\mathbb{R}$\n",
    "* $T_0, ..., T_K$ is a sequence of transitions functions $T_k: X_k \\times A_k \\rightarrow X_{k+1}$.\n",
    "* $\\beta$, a discount factor for utility between time steps **Or does this vary?***\n",
    "\n",
    "With these sequences of subproblems defined, the Bellman-like *Carroll equations* are:\n",
    "\n",
    "$$V_K(x) = \\text{max}_{a \\in \\Gamma_K(x)} F_K(x,a)$$\n",
    "$$V_k(x) = \\text{max}_{a \\in \\Gamma_k(x)} F_k(x,a) + \\beta V_{k+1}(T_k(x,a))$$\n",
    "\n",
    "Because this is a finite model, this can be solved simply via backwards induction without looking for a convergent value of $V_k$. Note that as before, the transition functions $T_k$ link the problem at $k$ to the state space of the next time $X_{k+1}$.\n",
    "\n",
    "If the problem for any $k$ carries as much information as one problem in the mode of **Definition 1**, then the time inconsistent problem will have a longer minimum description lengtht than the original infinite horizon problem. This is in contrast to the decomposition of the infinite horizon problem in to multiple stages based on multiple control variables; in the latter case, the decomposition contains no new information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carroll Problems: a proposed unified formalism\n",
    "   \n",
    "The two variations on the classic Bellman equation above have clear formal similarities, though they have some important differences as well. For the sake of clarity, we will formally define a *Carroll Problem* in a way that both kinds of variation, and others besides it, can be represented easily.\n",
    "\n",
    "A Carroll Problem $\\mathbb{C}$ is a set of subproblems $\\{\\mathcal{C}_0, ... \\mathcal{C}_I\\}$.\n",
    "\n",
    "Each subproblem $\\mathcal{C}_i$ is a tuple of the following:\n",
    "\n",
    "* A definition of the local problem:\n",
    "    * $A_i$, the set of actions available\n",
    "    * $X_i$, the set of states\n",
    "    * $\\Gamma_i : X \\rightarrow \\mathscr{B}(A)$ constraints the actions available in state X\n",
    "    * $F_i: X \\times A \\rightarrow \\mathbb{R}$ is the payoff to the agent of taking action $a$ in state $x$\n",
    "* A information about the transition to the next problem. This could be:\n",
    "    * Null, in which case the problem is terminal, or ...\n",
    "    * A tuple containing:\n",
    "        * An index to another subproblem $j$\n",
    "        * $T_i: X_i \\times A_i \\rightarrow X_j$, a transition function determining the state in the next problem\n",
    "        * $\\beta_i$ is a discount factor on future payoffs.\n",
    "\n",
    "The Carroll problem can then be solved using backwards induction by computing the value functions $V_i : X_i \\rightarrow \\mathbb{R}$:\n",
    "\n",
    "$$V_i(x) = \\text{max}_{a \\in \\Gamma_i(x)} F_i(x,a) + \\beta_i V_{j}(T_i(x,a))$$\n",
    "\n",
    "or for the terminal subproblems\n",
    "\n",
    "$$V_i(x) = \\text{max}_{a \\in \\Gamma_i(x)} F_i(x,a)$$\n",
    "\n",
    "Note that the connection between subproblems can be represented as a directed acyclic graph in the case of repetitions.\n",
    "\n",
    "**Quandary**. How does one represent an infinite horizon problem with a \"terminal solution\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing the relationship between subproblems of Portfolio Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"400px\" height=\"240px\" viewBox=\"0 0 73.274 37.264\" version=\"1.1\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.953125 -3.78125 C 3.78125 -3.78125 3.65625 -3.78125 3.515625 -3.65625 C 3.34375 -3.5 3.328125 -3.328125 3.328125 -3.265625 C 3.328125 -3.015625 3.515625 -2.90625 3.703125 -2.90625 C 3.984375 -2.90625 4.25 -3.15625 4.25 -3.546875 C 4.25 -4.03125 3.78125 -4.40625 3.078125 -4.40625 C 1.734375 -4.40625 0.40625 -2.984375 0.40625 -1.578125 C 0.40625 -0.671875 0.984375 0.109375 2.03125 0.109375 C 3.453125 0.109375 4.28125 -0.953125 4.28125 -1.0625 C 4.28125 -1.125 4.234375 -1.203125 4.171875 -1.203125 C 4.109375 -1.203125 4.09375 -1.171875 4.03125 -1.09375 C 3.25 -0.109375 2.15625 -0.109375 2.046875 -0.109375 C 1.421875 -0.109375 1.140625 -0.59375 1.140625 -1.203125 C 1.140625 -1.609375 1.34375 -2.578125 1.6875 -3.1875 C 2 -3.765625 2.546875 -4.1875 3.09375 -4.1875 C 3.421875 -4.1875 3.8125 -4.0625 3.953125 -3.78125 Z M 3.953125 -3.78125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.75 -2.359375 C 4.75 -3.921875 3.828125 -4.40625 3.09375 -4.40625 C 1.71875 -4.40625 0.40625 -2.984375 0.40625 -1.578125 C 0.40625 -0.640625 1 0.109375 2.03125 0.109375 C 2.65625 0.109375 3.375 -0.125 4.125 -0.734375 C 4.25 -0.203125 4.578125 0.109375 5.03125 0.109375 C 5.5625 0.109375 5.875 -0.4375 5.875 -0.59375 C 5.875 -0.671875 5.8125 -0.703125 5.75 -0.703125 C 5.6875 -0.703125 5.65625 -0.671875 5.625 -0.59375 C 5.4375 -0.109375 5.078125 -0.109375 5.0625 -0.109375 C 4.75 -0.109375 4.75 -0.890625 4.75 -1.125 C 4.75 -1.328125 4.75 -1.359375 4.859375 -1.46875 C 5.796875 -2.65625 6 -3.8125 6 -3.8125 C 6 -3.84375 5.984375 -3.921875 5.875 -3.921875 C 5.78125 -3.921875 5.78125 -3.890625 5.734375 -3.703125 C 5.546875 -3.078125 5.21875 -2.328125 4.75 -1.734375 Z M 4.09375 -0.984375 C 3.203125 -0.21875 2.4375 -0.109375 2.046875 -0.109375 C 1.453125 -0.109375 1.140625 -0.5625 1.140625 -1.203125 C 1.140625 -1.6875 1.40625 -2.765625 1.71875 -3.265625 C 2.1875 -4 2.734375 -4.1875 3.078125 -4.1875 C 4.0625 -4.1875 4.0625 -2.875 4.0625 -2.109375 C 4.0625 -1.734375 4.0625 -1.15625 4.09375 -0.984375 Z M 4.09375 -0.984375 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "<clipPath id=\"clip1\">\n",
       "  <path d=\"M 50 4 L 73.273438 4 L 73.273438 33 L 50 33 Z M 50 4 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip2\">\n",
       "  <path d=\"M 8 18 L 65 18 L 65 37.265625 L 8 37.265625 Z M 8 18 \"/>\n",
       "</clipPath>\n",
       "</defs>\n",
       "<g id=\"surface1\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 7.703469 -0.0008125 C 7.703469 4.253094 4.25425 7.702313 0.00034375 7.702313 C -4.253563 7.702313 -7.702781 4.253094 -7.702781 -0.0008125 C -7.702781 -4.254719 -4.253563 -7.703937 0.00034375 -7.703937 C 4.25425 -7.703937 7.703469 -4.254719 7.703469 -0.0008125 Z M 7.703469 -0.0008125 \" transform=\"matrix(1,0,0,-1,7.902,18.632)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"5.746\" y=\"20.777\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip1)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 65.172219 -0.0008125 C 65.172219 4.682781 61.375344 8.479656 56.69175 8.479656 C 52.012062 8.479656 48.215187 4.682781 48.215187 -0.0008125 C 48.215187 -4.684406 52.012062 -8.481281 56.69175 -8.481281 C 61.375344 -8.481281 65.172219 -4.684406 65.172219 -0.0008125 Z M 65.172219 -0.0008125 \" transform=\"matrix(1,0,0,-1,7.902,18.632)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"61.39\" y=\"20.777\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 5.586281 5.589031 C 17.883156 18.186688 37.957375 18.432781 50.226906 6.456219 \" transform=\"matrix(1,0,0,-1,7.902,18.632)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196895 1.593927 C -1.096775 0.995056 -0.000497247 0.100376 0.298488 0.000340274 C -0.000191255 -0.100681 -1.096234 -0.996207 -1.194384 -1.592664 \" transform=\"matrix(0.71779,0.70052,0.70052,-0.71779,58.12926,12.17396)\"/>\n",
       "<g clip-path=\"url(#clip2)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 50.555031 -6.137531 C 37.957375 -18.434406 17.883156 -18.188312 5.9105 -5.914875 \" transform=\"matrix(1,0,0,-1,7.902,18.632)\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.195239 1.594397 C -1.094301 0.99522 0.00174119 0.0996935 0.297633 0.00139259 C -0.00135209 -0.0986435 -1.094842 -0.996043 -1.194962 -1.594915 \" transform=\"matrix(-0.70052,-0.71779,-0.71779,0.70052,13.81106,24.5486)\"/>\n",
       "</g>\n",
       "</svg>"
      ]
     },
     "metadata": {
      "isolated": "true"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%tikz -f svg\n",
    "\n",
    "\\usetikzlibrary{shapes}\n",
    "\n",
    "\\node[shape=circle,draw=black] (c) at (0,0) {$c$};\n",
    "\\node[shape=circle,draw=black] (alpha) at (2,0) {$\\alpha$};\n",
    "\n",
    "\\path [->] (c) edge [bend left=45] node[left] {} (alpha);\n",
    "\\path [->] (alpha) edge [bend left=45] node[right] {} (c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Modeling Desiderata\n",
    "\n",
    "Once we have all of the information necessary to define a problem, we may be inclined to reshape it into a more tractable form. In general, we would like our models to be easy to understand and easy to solve. These two desiderata may be at odds with each other and can be addressed separately.\n",
    "\n",
    "* D1. Minimal computational complexity of solution\n",
    "* D2. Minimal programmatic description.\n",
    "\n",
    "#### D1. Minimal computational complexity of solution\n",
    "\n",
    "#### D2. Minimal programmatic description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "### HARK 1.0\n",
    "\n",
    "#### Shocks, State, Control, and Reward variables\n",
    "\n",
    "Consider this version of the portfolio choice consumption saving problem.\n",
    "\n",
    "Variable | Equation | Operation | Stage | Utility\n",
    "-- | -- | -- | -- | --\n",
    "\\Risky | ~Dist | Shock | c | --\n",
    "\\TranShk | ~Dist | Shock | c | --\n",
    "\\PermShk | ~Dist | Shock | c | --\n",
    "\\Rport | \\Rport = \\PortShare * \\Risky + (1 - \\PortShare) * R | Update | c | --\n",
    "$b$ | b_{t} = a_{t-1} \\RPort | Update | c | --\n",
    "$p$ | p_{t}=p_{t-1}\\PermShk_{t} | Update | c | --\n",
    "$y$ | y_{t} = p_{t}\\TranShk_{t} | Update | c | --\n",
    "$m$ | m_{t} = b_{t} + y_{t} | Update | c | --\n",
    "$c$ | c | Control | c | U(c)\n",
    "$a$ | a_{t} = m_{t} - c_{t} | Update | $\\alpha$ | --\n",
    "$\\alpha$| $\\alpha$ | Control | $\\alpha$ | 0\n",
    "\n",
    "Here, there are threes kinds of variables: shocks ($\\phi$, $\\psi$, ...), state ($a$, $b$, ...)  and control ($c$ and $\\PortShare$).\n",
    "\n",
    "There is also another kind of value, a reward or utility value that in this case is dependent on a control variable.\n",
    "\n",
    "#### Finite Horizon iteration\n",
    "\n",
    "Repeat a problem a finite number of time $T$.\n",
    "\n",
    "\n",
    "#### Backwards induction\n",
    "\n",
    "For each control variable, compute the optimal policy.\n",
    "\n",
    "This is done through the calculation of the Bellman equation:\n",
    "\n",
    "$$V(x) = \\text{max}_{a \\in \\Gamma(a)} F(x,a) + \\beta V(T(x,a))  $$\n",
    "\n",
    "Where $\\Gamma$ are constraints on the actions available and $T$ is the transition function to the next state.\n",
    "\n",
    "Note in this formulation $a$ and $x$ are considered in terms of the broader classes of State and Action \n",
    "\n",
    "Compute this with a time adjusted value function \n",
    "\n",
    "\n",
    "\n",
    "#### Market equilibria\n",
    "\n",
    "Multiple agents interacting with a Market, with rational expectations of the behavior of the market.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HARK 2.0\n",
    "\n",
    "#### Arbitrary Problem Embeddings\n",
    "\n",
    "Let a problem be defined as as set containing:\n",
    " - \n",
    " - \n",
    " - \n",
    " - \n",
    " - \n",
    " - \n",
    " \n",
    "(This is all the information included in a Dolang document).\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior work\n",
    "\n",
    "### Modeling different kinds of variables\n",
    "\n",
    "Koller and Milch (2003) take the approach in their Multi-Agent Influence Diagrams (MAIDs) of using:\n",
    " - ovals for Chance variables or \"decisions by nature\"\n",
    " - rectangles for Decision variables (roughly equivalent to Control variables here)\n",
    " - diamonds for Utility variables, which correspond to utility gained by the agents.\n",
    " \n",
    " We can adapt this to the portfolio choice model as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "There exist a number of tools that are designed for flexible notation for visualizing [probabilistic graphical models](http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture4.pdf) (see also [Koller and Friedman, 2009](https://djsaunde.github.io/read/books/pdfs/probabilistic%20graphical%20models.pdf))\n",
    "\n",
    "\n",
    "### tikz BayesNet\n",
    "\n",
    "https://github.com/jluttine/tikz-bayesnet\n",
    "\n",
    "* LaTeX, builds on [Tikz](https://es.overleaf.com/learn/latex/TikZ_package)\n",
    "* Plate notation\n",
    "* Can handle factor graphs\n",
    "\n",
    "### Daft\n",
    "\n",
    "https://docs.daft-pgm.org/en/latest/\n",
    "\n",
    "* Python based, used `matplotlib`\n",
    "* Programmatic graph definition is nice\n",
    "* built-in distinction between 'observed' and 'unobserved' variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GraphViz\n",
    "\n",
    "https://stackoverflow.com/a/16334517\n",
    "\n",
    "* Most flexible\n",
    "* not LaTeX native\n",
    "* Requires additional C dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"390pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 389.98 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 385.9839,-112 385.9839,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"190.9919\" cy=\"-90\" rx=\"53.8905\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.9919\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">King Arthur</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"90.9919\" cy=\"-18\" rx=\"90.9839\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"90.9919\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Sir Bedevere the Wise</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M168.3004,-73.6621C155.1015,-64.1589 138.2402,-52.0188 123.6348,-41.5029\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"125.5012,-38.5339 115.3408,-35.5312 121.4111,-44.2146 125.5012,-38.5339\"/>\n",
       "</g>\n",
       "<!-- L -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>L</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"290.9919\" cy=\"-18\" rx=\"90.9839\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"290.9919\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Sir Lancelot the Brave</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;L -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M213.6835,-73.6621C226.8824,-64.1589 243.7437,-52.0188 258.3491,-41.5029\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.5728,-44.2146 266.6431,-35.5312 256.4826,-38.5339 260.5728,-44.2146\"/>\n",
       "</g>\n",
       "<!-- B&#45;&gt;L -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.0076,-18C184.6151,-18 187.2226,-18 189.8302,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.8878,-21.5001 199.8878,-18 189.8878,-14.5001 189.8878,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f15b8300b20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz as gv\n",
    "\n",
    "dot = gv.Digraph(comment='The Round Table')\n",
    "\n",
    "dot.node('A', 'King Arthur')\n",
    "dot.node('B', 'Sir Bedevere the Wise')\n",
    "dot.node('L', 'Sir Lancelot the Brave')\n",
    "\n",
    "dot.edges(['AB', 'AL'])\n",
    "dot.edge('B', 'L', constraint='false')\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "Koller, D., & Milch, B. (2003). Multi-agent influence diagrams for representing and solving games. Games and economic behavior, 45(1), 181-221.\n",
    "\n",
    "Koller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ-ark-3.8",
   "language": "python",
   "name": "econ-ark-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
